import streamlit as st
from model_reasoner_api import get_reasoner_response
import time
# import asyncio

st.set_page_config(page_title="ICH Copilot with Reasoning", page_icon="ğŸ¦œ")
st.title("ğŸ¦œ ICH Copilot with Reasoning")

# åœ¨ä¾§è¾¹æ æ·»åŠ é…ç½®é€‰é¡¹  
with st.sidebar:  
    with st.expander("LLMæ¨¡å‹APIè®¾ç½®", expanded=False):
        # æä¾›ä¸€ä¸ªæ–‡æœ¬è¾“å…¥æ¡†è®©ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è¾“å…¥API Keyï¼ˆå¯é€‰ï¼‰  
        st.markdown('<span style="font-size: 14px;">å†…ç½®deepseekæ¨¡å‹ä¸ºå…è´¹æ¨¡å‹ï¼Œå¦‚æœå­˜åœ¨å¡é¡¿æˆ–è€…è¶…æ—¶é—®é¢˜ï¼Œå»ºè®®æ¥å…¥è‡ªå·±çš„Deepseek API</span>', unsafe_allow_html=True)
        api_base = st.text_input("Base Url", key="chatbot_api_base", type="default", 
                                 placeholder="https://api.deepseek.com/v1")  
        api_key = st.text_input("API Key", key="chatbot_api_key", type="password", 
                                placeholder="sk-9ee206fef1134798a880a7e328c77dd7")  
        model = st.text_input("Model",key="chatbot_model", type="default",
                              placeholder="deepseek-reasoner")
        "[è·å– DeepSeek API key](https://platform.deepseek.com/api_keys)"  

def init_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []

def display_chat_history():
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

def main():    
    init_session_state()
    display_chat_history()
    
    if prompt := st.chat_input("What is your question?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        with st.chat_message("assistant"):
            # åˆ›å»ºä¸€ä¸ªexpanderæ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œreason_containerç”¨æ¥æ”¾ç½®æ€è€ƒè¿‡ç¨‹çš„æ–‡æœ¬
            with st.expander("æ€è€ƒä¸­...", expanded=True):
                reason_container = st.empty()
            answer_container = st.empty()

            answer_content = ""
            reasoning_content = ""
            stream_phase = "notstart"
            print("model: ", model)
            print("api_base: ", api_base)
            print("api_key: ", api_key)
            for chunk in get_reasoner_response(prompt,model, api_base, api_key):
                chunk_cleaned  = chunk\
                    .replace("<think_start>", "")\
                    .replace("<think_end>", "")
                
                if(chunk.find("<think_start>") != -1):
                    stream_phase = "thinking"
                    continue

                if(chunk.find("<think_end>") != -1):
                    stream_phase = "answering"
                    continue

                if stream_phase == "thinking":
                    reasoning_content += chunk_cleaned
                    with st.expander("æ€è€ƒä¸­...", expanded=True):
                        reason_container.markdown(reasoning_content+"â–Œ")

                if stream_phase == "answering":
                    answer_content += chunk_cleaned
                    answer_container.markdown(answer_content+"â–Œ")
                time.sleep(0.05)
            answer_container.markdown(answer_content)

            
        if answer_content != "":  # åªåœ¨æˆåŠŸè·å¾—å“åº”æ—¶æ·»åŠ åˆ°å†å²è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": answer_content})

if __name__ == "__main__":
    main()