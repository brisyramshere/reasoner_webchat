import streamlit as st
from model_reasoner_api import get_reasoner_response
import time
import re

st.set_page_config(page_title="ICH Copilot with Reasoning", page_icon="ğŸ¦œ")
st.title("ğŸ§  ICH Copilot with Reasoning ğŸ”âœ…ğŸ“ğŸ“„")

def init_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = []

def format_response(response: str):
    """å°†å“åº”æ–‡æœ¬åˆ†å‰²æˆæ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆ"""
    think_pattern = r'<think_start>(.*?)<think_end>'
    think_parts = re.findall(think_pattern, response, re.DOTALL)
    final_response = re.sub(think_pattern, '', response).strip()
    return think_parts, final_response

def stream_display(placeholder, response, thinking_placeholder=None):
    """å¤„ç†æµå¼è¾“å‡ºçš„æ˜¾ç¤º"""
    think_parts, final_response = format_response(response)
    
    # æ›´æ–°æ€è€ƒè¿‡ç¨‹
    if think_parts and thinking_placeholder is not None:
        think_text = ""
        for i, think in enumerate(think_parts, 1):
            think_text += f"**æ€è€ƒæ­¥éª¤ {i}:**\n{think.strip()}\n\n"
        thinking_placeholder.markdown(think_text)
    
    # æ›´æ–°æœ€ç»ˆç­”æ¡ˆ
    if final_response:
        placeholder.markdown(final_response + "â–Œ ")

def display_message(message):
    """æ˜¾ç¤ºå†å²æ¶ˆæ¯"""
    think_parts, final_response = format_response(message)
    
    # å¦‚æœæœ‰æ€è€ƒè¿‡ç¨‹ï¼Œæ˜¾ç¤ºåœ¨å¯æŠ˜å åŒºåŸŸ
    if think_parts:
        with st.expander("ğŸ’­ æŸ¥çœ‹æ€è€ƒè¿‡ç¨‹", expanded=False):
            for i, think in enumerate(think_parts, 1):
                st.markdown(f"**æ€è€ƒæ­¥éª¤ {i}:**")
                st.markdown(think.strip())
    
    # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
    if final_response:
        st.markdown(final_response)

def display_chat_history():
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            display_message(message["content"])

def main():    
    init_session_state()
    display_chat_history()
    
    if prompt := st.chat_input("What is your question?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
            
        with st.chat_message("assistant"):
            # åˆ›å»ºä¸¤ä¸ªå ä½ç¬¦ï¼šä¸€ä¸ªç”¨äºæ€è€ƒè¿‡ç¨‹ï¼Œä¸€ä¸ªç”¨äºæœ€ç»ˆç­”æ¡ˆ
            thinking_placeholder = st.empty()
            answer_placeholder = st.empty()
            
            full_response = ""
            
            # æµå¼è¾“å‡ºå¤„ç†
            for chunk in get_reasoner_response(prompt):
                full_response += chunk
                stream_display(answer_placeholder, full_response, thinking_placeholder)
                time.sleep(0.05)
            
            # æ¸…ç†æµå¼è¾“å‡ºçš„ç—•è¿¹ï¼Œé‡æ–°æ˜¾ç¤ºå®Œæ•´å“åº”
            thinking_placeholder.empty()
            answer_placeholder.empty()
            display_message(full_response)
            
        if full_response:
            st.session_state.messages.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()